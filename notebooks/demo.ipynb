{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bae3e24-a48f-4c22-b840-8cfe8007ed52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "from delta.tables import DeltaTable\n",
    "from loguru import logger\n",
    "from typing import Mapping, Iterable, Union\n",
    "\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import DataFrame, SparkSession, Window\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession, types as T\n",
    "\n",
    "from event_sessions.utils.spark import create_conf, DEFAULT_CONF\n",
    "from event_sessions.utils.parameters import USER_ACTION_IDS, INACTIVITY_SECONDS\n",
    "from event_sessions.sessions.events_to_sessions import rewrite_impacted_users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391c2b40-e8e9-4183-8651-2cd082984063",
   "metadata": {},
   "source": [
    "# SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296f647c-27c3-4e0b-be78-79be4eae65ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFAULT_CONF = {\n",
    "#     \"spark.app.name\": \"sessions\",\n",
    "#     \"spark.master\": \"local[*]\",\n",
    "#     \"spark.sql.session.timeZone\": \"UTC\",\n",
    "#     \"spark.sql.shuffle.partitions\": \"200\",\n",
    "#     \"spark.default.parallelism\": \"200\",\n",
    "#     \"spark.sql.extensions\": \"io.delta.sql.DeltaSparkSessionExtension\",\n",
    "#     \"spark.sql.catalog.spark_catalog\": \"org.apache.spark.sql.delta.catalog.DeltaCatalog\",\n",
    "#     \"spark.jars.packages\": \"io.delta:delta-spark_2.12:3.2.0\",\n",
    "#     \"spark.sql.warehouse.dir\": \"./spark-warehouse\",\n",
    "#     \"spark.driver.memory\": \"1g\",\n",
    "#     \"spark.sql.adaptive.enabled\": \"true\",\n",
    "#     \"spark.sql.adaptive.coalescePartitions.enabled\": \"true\",\n",
    "#     \"spark.sql.adaptive.advisoryPartitionSizeInBytes\": \"268435456\",  # 256MB\n",
    "# }\n",
    "\n",
    "spark_config = create_conf(DEFAULT_CONF)\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"sessions\")\n",
    "    .enableHiveSupport()\n",
    "    .config(conf=spark_config)\n",
    "    .config(\"spark.ui.enabled\", \"true\")\n",
    "    .config(\"spark.ui.port\", \"4040\")\n",
    "    .config(\"spark.driver.bindAddress\", \"0.0.0.0\")\n",
    "    .config(\"spark.driver.host\", \"localhost\")\n",
    "    .config(\"spark.publicDns\", \"localhost\")\n",
    "    .config(\"spark.driver.extraJavaOptions\", \"-Djava.net.preferIPv4Stack=true\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91753054-a1d6-406c-b20b-a8b0f5871817",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d353529-184a-44ca-9847-d119e56028a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"/home/demon/jetbrains/github/sessions/data/demo/csv/events\"\n",
    "output_path = \"/home/demon/jetbrains/github/sessions/data/demo/sessions\"\n",
    "\n",
    "run_date_str = \"2025-09-20\"  # which ingest partition to read"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c329429-16d5-49b5-9a20-bbaa956f4cd4",
   "metadata": {},
   "source": [
    "# Step 0: create delta (just once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2c2a65-2a2d-4675-996b-d7d459ff00bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: create delta (just once)\n",
    "# schema = T.StructType([\n",
    "#     T.StructField(\"user_id\", T.StringType(), True),\n",
    "#     T.StructField(\"event_id\", T.StringType(), True),\n",
    "#     T.StructField(\"product_code\", T.StringType(), True),\n",
    "#     T.StructField(\"timestamp\", T.TimestampType(), True),\n",
    "#     T.StructField(\"event_date\", T.DateType(), True),\n",
    "#     T.StructField(\"session_start_ts\", T.TimestampType(), True),\n",
    "#     T.StructField(\"session_end_ts\", T.TimestampType(), True),\n",
    "#     T.StructField(\"session_id\", T.StringType(), True),\n",
    "# ])\n",
    "\n",
    "# (\n",
    "#     spark.createDataFrame([], schema)\n",
    "#         .write.format(\"delta\")\n",
    "#         .mode(\"overwrite\")\n",
    "#         .partitionBy(\"event_date\")\n",
    "#         .save(output_path)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fc0b89-bab7-4f9c-9fdb-ae6a668dfad2",
   "metadata": {},
   "source": [
    "# Step 1: Daily raw partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99c7b63a-ae17-4ef0-835b-2993d2f12129",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-25 00:59:09.532\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[34m\u001b[1m[DEBUG] read_partition_path=/home/demon/jetbrains/github/sessions/data/demo/csv/events/date=2025-09-20\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------------+-------------------+----------+\n",
      "|user_id|event_id|product_code|timestamp          |event_date|\n",
      "+-------+--------+------------+-------------------+----------+\n",
      "|u1     |a       |pyc         |2025-09-18 09:00:00|2025-09-18|\n",
      "|u1     |z       |pyc         |2025-09-18 09:03:00|2025-09-18|\n",
      "|u1     |b       |pyc         |2025-09-18 09:04:59|2025-09-18|\n",
      "|u1     |y       |pyc         |2025-09-18 09:10:30|2025-09-18|\n",
      "|u1     |a       |pyc         |2025-09-18 10:00:00|2025-09-18|\n",
      "|u1     |x       |pyc         |2025-09-18 10:02:00|2025-09-18|\n",
      "|u1     |c       |pyc         |2025-09-18 10:07:01|2025-09-18|\n",
      "|u2     |b       |pyc         |2025-09-20 23:58:00|2025-09-20|\n",
      "|u2     |x       |pyc         |2025-09-20 00:02:00|2025-09-20|\n",
      "|u2     |c       |pyc         |2025-09-20 00:02:59|2025-09-20|\n",
      "|u2     |d       |pyc         |2025-09-20 00:10:00|2025-09-20|\n",
      "|u3     |x       |idea        |2025-09-18 12:00:00|2025-09-18|\n",
      "+-------+--------+------------+-------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Read the daily raw partition\n",
    "# run_date_str = run_date.date().strftime(\"%Y-%m-%d\")\n",
    "read_partition_path = f\"{input_path}/date={run_date_str}\"\n",
    "logger.debug(f\"[DEBUG] read_partition_path={read_partition_path}\")\n",
    "\n",
    "# read from csv (there is parquet in the main job)\n",
    "df_raw = (\n",
    "    spark.read.option(\"header\", True).csv(read_partition_path, inferSchema=True)\n",
    "      .select(\"user_id\",\"event_id\",\"product_code\",F.col(\"timestamp\").cast(\"timestamp\").alias(\"timestamp\"))\n",
    ")\n",
    "\n",
    "df = (\n",
    "    df_raw.select(\n",
    "        F.col(\"user_id\").cast(\"string\").alias(\"user_id\"),\n",
    "        F.col(\"event_id\").cast(\"string\").alias(\"event_id\"),\n",
    "        F.col(\"product_code\").cast(\"string\").alias(\"product_code\"),\n",
    "        F.col(\"timestamp\").cast(\"timestamp\").alias(\"timestamp\"),\n",
    "    )\n",
    "    .withColumn(\"event_date\", F.to_date(\"timestamp\"))\n",
    ")\n",
    "\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c01a30-60ce-4d42-85d2-959417b85345",
   "metadata": {},
   "source": [
    "# Step 2: Compute all dates / timestamps - dmin..dmax are the actual event_date bounds inside today's batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bfa11b9-5b3f-45fd-8ec0-c9e59e5af322",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-25 00:59:11.697\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mDates: run_date_str=2025-09-20, ctx=[2025-09-17 00:00:00 .. 2025-09-22 00:00:00), write=[2025-09-18 00:00:00 .. 2025-09-22 00:00:00), new batch dates=[2025-09-18 .. 2025-09-21]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Compute all dates / timestamps - dmin..dmax are the actual event_date bounds inside today's batch\n",
    "mm = df.agg(\n",
    "    F.min(\"event_date\").alias(\"dmin\"),\n",
    "    F.max(\"event_date\").alias(\"dmax\")\n",
    ").first()\n",
    "dmin, dmax = mm[\"dmin\"], mm[\"dmax\"]\n",
    "\n",
    "# Context window for building sessions: [ctx_left_ts, ctx_right_ts_excl)\n",
    "left_ctx_date = dmin - timedelta(days=1)  # look back 1 day\n",
    "right_ctx_date = dmax + timedelta(days=1)  # look ahead 1 day\n",
    "ctx_left_ts = f\"{left_ctx_date} 00:00:00\"\n",
    "ctx_right_ts_excl = f\"{(right_ctx_date + timedelta(days=1))} 00:00:00\"  # = dmax+2 00:00\n",
    "\n",
    "# Write window: rewrite impacted users for [dmin .. dmax+1]\n",
    "write_left_date = dmin\n",
    "write_right_date = dmax + timedelta(days=1)\n",
    "write_left_ts = f\"{dmin} 00:00:00\"\n",
    "write_right_ts_excl = f\"{(dmax + timedelta(days=2))} 00:00:00\"  # = dmax+2 00:00\n",
    "\n",
    "logger.info(\n",
    "    f\"Dates: run_date_str={run_date_str}, \"\n",
    "    f\"ctx=[{ctx_left_ts} .. {ctx_right_ts_excl}), \"\n",
    "    f\"write=[{write_left_ts} .. {write_right_ts_excl}), \"\n",
    "    f\"new batch dates=[{write_left_date} .. {write_right_date}]\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae43517-8ca8-41de-8545-33bfa334a6a6",
   "metadata": {},
   "source": [
    "# Step 3: Detect impacted keys to limit IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "173fe217-d7ef-4bda-bae2-e5bb79cd682e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+\n",
      "|user_id|product_code|\n",
      "+-------+------------+\n",
      "|u3     |idea        |\n",
      "|u1     |pyc         |\n",
      "|u2     |pyc         |\n",
      "+-------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Detect impacted keys to limit IO\n",
    "impacted_keys = df.select(\"user_id\", \"product_code\").distinct()\n",
    "impacted_keys.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221ebb37-f811-4e8d-a5f1-5884a7442ec5",
   "metadata": {},
   "source": [
    "# Step 4: Read Delta once for impacted keys, then split into ctx/write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd46b6b1-b702-41f4-8b6e-6c24b42cc110",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/25 00:59:15 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+--------+---------+----------+\n",
      "|user_id|product_code|event_id|timestamp|event_date|\n",
      "+-------+------------+--------+---------+----------+\n",
      "+-------+------------+--------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Read Delta once for impacted keys, then split into ctx/write\n",
    "existing_superset = (\n",
    "    spark.read.format(\"delta\").load(output_path)\n",
    "    .select(\"user_id\", \"event_id\", \"product_code\", \"timestamp\", \"event_date\")\n",
    "    .join(impacted_keys, [\"user_id\", \"product_code\"], \"inner\")\n",
    "    .where(\n",
    "        (F.col(\"timestamp\") >= F.lit(ctx_left_ts)) &\n",
    "        (F.col(\"timestamp\") < F.lit(ctx_right_ts_excl))\n",
    "    )\n",
    "    .cache()  # TODO: not necessary but possible\n",
    ")\n",
    "existing_superset.count()\n",
    "\n",
    "existing_ctx = existing_superset\n",
    "existing_write = existing_superset.where(\n",
    "    (F.col(\"timestamp\") >= F.lit(write_left_ts)) &\n",
    "    (F.col(\"timestamp\") < F.lit(write_right_ts_excl))\n",
    ")\n",
    "\n",
    "existing_superset.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fa6a98-5f2e-4576-ba7c-aa538e1c6c65",
   "metadata": {},
   "source": [
    "# Step 5: Build sessions over (new + context) only for impacted keys - Basic session detection logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "559ec5ee-7a35-457b-9757-0566393c4142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+-------------------+-------------------+-------------------+-------------------------------+\n",
      "|user_id|product_code|session_start_ts   |last_user_action_ts|session_end_ts     |session_id                     |\n",
      "+-------+------------+-------------------+-------------------+-------------------+-------------------------------+\n",
      "|u1     |pyc         |2025-09-18 09:00:00|2025-09-18 09:04:59|2025-09-18 09:09:59|u1#pyc#2025-09-18T09:00:00.000Z|\n",
      "|u1     |pyc         |2025-09-18 10:00:00|2025-09-18 10:00:00|2025-09-18 10:05:00|u1#pyc#2025-09-18T10:00:00.000Z|\n",
      "|u1     |pyc         |2025-09-18 10:07:01|2025-09-18 10:07:01|2025-09-18 10:12:01|u1#pyc#2025-09-18T10:07:01.000Z|\n",
      "|u2     |pyc         |2025-09-20 00:02:59|2025-09-20 00:02:59|2025-09-20 00:07:59|u2#pyc#2025-09-20T00:02:59.000Z|\n",
      "|u2     |pyc         |2025-09-20 23:58:00|2025-09-20 23:58:00|2025-09-21 00:03:00|u2#pyc#2025-09-20T23:58:00.000Z|\n",
      "+-------+------------+-------------------+-------------------+-------------------+-------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Build sessions over (new + context) only for impacted keys - Basic session detection logic\n",
    "all_for_sessions = df.select(\n",
    "    \"user_id\", \"event_id\", \"product_code\", \"timestamp\", \"event_date\"\n",
    ").unionByName(\n",
    "    existing_ctx.select(\"user_id\", \"event_id\", \"product_code\", \"timestamp\", \"event_date\")\n",
    ")\n",
    "\n",
    "df_window = (\n",
    "    all_for_sessions\n",
    "    .where(\n",
    "        (F.col(\"timestamp\") >= F.lit(ctx_left_ts)) &\n",
    "        (F.col(\"timestamp\") < F.lit(ctx_right_ts_excl))\n",
    "    )\n",
    "    .repartition(\"user_id\", \"product_code\")   # reduce skew\n",
    ")\n",
    "\n",
    "ua = (\n",
    "    df_window\n",
    "    .filter(F.col(\"event_id\").isin([*USER_ACTION_IDS]))\n",
    "    .select(\"user_id\", \"product_code\", F.col(\"timestamp\").alias(\"ts\"))\n",
    ")\n",
    "\n",
    "w = Window.partitionBy(\"user_id\", \"product_code\").orderBy(\"ts\")\n",
    "ua = ua.withColumn(\"prev_ts\", F.lag(\"ts\").over(w))\n",
    "ua = ua.withColumn(\n",
    "    \"is_new\",\n",
    "    F.when(\n",
    "        F.col(\"prev_ts\").isNull() |\n",
    "        ((F.col(\"ts\").cast(\"long\") - F.col(\"prev_ts\").cast(\"long\")) >= INACTIVITY_SECONDS),\n",
    "        F.lit(1)\n",
    "    ).otherwise(F.lit(0))\n",
    ")\n",
    "ua = ua.withColumn(\n",
    "    \"sess_seq\",\n",
    "    F.sum(\"is_new\").over(w.rowsBetween(Window.unboundedPreceding, Window.currentRow))\n",
    ")\n",
    "\n",
    "w_sess = Window.partitionBy(\"user_id\", \"product_code\", \"sess_seq\")\n",
    "sessions = (\n",
    "    ua\n",
    "    .withColumn(\"session_start_ts\", F.min(\"ts\").over(w_sess))\n",
    "    .withColumn(\"last_user_action_ts\", F.max(\"ts\").over(w_sess))\n",
    "    .select(\"user_id\", \"product_code\", \"sess_seq\", \"session_start_ts\", \"last_user_action_ts\")\n",
    "    .dropDuplicates([\"user_id\", \"product_code\", \"sess_seq\"])\n",
    "    .withColumn(\n",
    "        \"session_end_ts\",\n",
    "        F.expr(f\"last_user_action_ts + INTERVAL {INACTIVITY_SECONDS} SECONDS\")\n",
    "    )\n",
    "    .drop(\"sess_seq\")\n",
    "    .withColumn(\n",
    "        \"session_id\",\n",
    "        F.concat_ws(\n",
    "            \"#\",\n",
    "            F.col(\"user_id\"),\n",
    "            F.col(\"product_code\"),\n",
    "            F.date_format(F.col(\"session_start_ts\"), \"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\")\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "sessions.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5b800d-12a6-46da-bfd9-acf5d9c8143b",
   "metadata": {},
   "source": [
    "# Step 6: Full write set for [dmin .. dmax+1] - keep existing + add missing new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4d7db8d-2a43-4f03-9572-c63154321f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+--------+-------------------+----------+\n",
      "|user_id|product_code|event_id|timestamp          |event_date|\n",
      "+-------+------------+--------+-------------------+----------+\n",
      "|u1     |pyc         |a       |2025-09-18 09:00:00|2025-09-18|\n",
      "|u1     |pyc         |z       |2025-09-18 09:03:00|2025-09-18|\n",
      "|u1     |pyc         |b       |2025-09-18 09:04:59|2025-09-18|\n",
      "|u1     |pyc         |y       |2025-09-18 09:10:30|2025-09-18|\n",
      "|u1     |pyc         |a       |2025-09-18 10:00:00|2025-09-18|\n",
      "|u1     |pyc         |x       |2025-09-18 10:02:00|2025-09-18|\n",
      "|u1     |pyc         |c       |2025-09-18 10:07:01|2025-09-18|\n",
      "|u2     |pyc         |b       |2025-09-20 23:58:00|2025-09-20|\n",
      "|u2     |pyc         |x       |2025-09-20 00:02:00|2025-09-20|\n",
      "|u2     |pyc         |c       |2025-09-20 00:02:59|2025-09-20|\n",
      "|u2     |pyc         |d       |2025-09-20 00:10:00|2025-09-20|\n",
      "|u3     |idea        |x       |2025-09-18 12:00:00|2025-09-18|\n",
      "+-------+------------+--------+-------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Full write set for [dmin .. dmax+1] - keep existing + add missing new\n",
    "new_only = (\n",
    "    df.where(\n",
    "        (F.col(\"timestamp\") >= F.lit(write_left_ts)) &\n",
    "        (F.col(\"timestamp\") < F.lit(write_right_ts_excl))\n",
    "    )\n",
    "    .join(\n",
    "        existing_write.select(\"user_id\", \"product_code\", \"timestamp\").distinct(),\n",
    "        on=[\"user_id\", \"product_code\", \"timestamp\"],\n",
    "        how=\"left_anti\"\n",
    "    )\n",
    ")\n",
    "\n",
    "to_write_base = existing_write.unionByName(new_only)\n",
    "\n",
    "to_write_base.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1082ded5-6a0c-42d0-8516-96c12f97dd94",
   "metadata": {},
   "source": [
    "# Step 7: Assign session_id to all events in the write window (broadcast range join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac0961ec-0eb9-4caf-9af5-69c722f018fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------------+-------------------+----------+-------------------+-------------------+-------------------------------+\n",
      "|user_id|event_id|product_code|timestamp          |event_date|session_start_ts   |session_end_ts     |session_id                     |\n",
      "+-------+--------+------------+-------------------+----------+-------------------+-------------------+-------------------------------+\n",
      "|u1     |a       |pyc         |2025-09-18 09:00:00|2025-09-18|2025-09-18 09:00:00|2025-09-18 09:09:59|u1#pyc#2025-09-18T09:00:00.000Z|\n",
      "|u1     |z       |pyc         |2025-09-18 09:03:00|2025-09-18|2025-09-18 09:00:00|2025-09-18 09:09:59|u1#pyc#2025-09-18T09:00:00.000Z|\n",
      "|u1     |b       |pyc         |2025-09-18 09:04:59|2025-09-18|2025-09-18 09:00:00|2025-09-18 09:09:59|u1#pyc#2025-09-18T09:00:00.000Z|\n",
      "|u1     |y       |pyc         |2025-09-18 09:10:30|2025-09-18|NULL               |NULL               |NULL                           |\n",
      "|u1     |a       |pyc         |2025-09-18 10:00:00|2025-09-18|2025-09-18 10:00:00|2025-09-18 10:05:00|u1#pyc#2025-09-18T10:00:00.000Z|\n",
      "|u1     |x       |pyc         |2025-09-18 10:02:00|2025-09-18|2025-09-18 10:00:00|2025-09-18 10:05:00|u1#pyc#2025-09-18T10:00:00.000Z|\n",
      "|u1     |c       |pyc         |2025-09-18 10:07:01|2025-09-18|2025-09-18 10:07:01|2025-09-18 10:12:01|u1#pyc#2025-09-18T10:07:01.000Z|\n",
      "|u2     |b       |pyc         |2025-09-20 23:58:00|2025-09-20|2025-09-20 23:58:00|2025-09-21 00:03:00|u2#pyc#2025-09-20T23:58:00.000Z|\n",
      "|u2     |x       |pyc         |2025-09-20 00:02:00|2025-09-20|NULL               |NULL               |NULL                           |\n",
      "|u2     |c       |pyc         |2025-09-20 00:02:59|2025-09-20|2025-09-20 00:02:59|2025-09-20 00:07:59|u2#pyc#2025-09-20T00:02:59.000Z|\n",
      "|u2     |d       |pyc         |2025-09-20 00:10:00|2025-09-20|NULL               |NULL               |NULL                           |\n",
      "|u3     |x       |idea        |2025-09-18 12:00:00|2025-09-18|NULL               |NULL               |NULL                           |\n",
      "+-------+--------+------------+-------------------+----------+-------------------+-------------------+-------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Assign session_id to all events in the write window (broadcast range join)\n",
    "s_for_join = sessions.select(\n",
    "    F.col(\"user_id\").alias(\"s_user_id\"),\n",
    "    F.col(\"product_code\").alias(\"s_product_code\"),\n",
    "    \"session_start_ts\", \"session_end_ts\", \"session_id\"\n",
    ")\n",
    "\n",
    "updates = (\n",
    "    to_write_base\n",
    "    .withColumn(\"ts\", F.col(\"timestamp\"))\n",
    "    .join(\n",
    "        F.broadcast(s_for_join),\n",
    "        on=[\n",
    "            F.col(\"user_id\") == F.col(\"s_user_id\"),\n",
    "            F.col(\"product_code\") == F.col(\"s_product_code\"),\n",
    "            F.col(\"ts\") >= F.col(\"session_start_ts\"),\n",
    "            F.col(\"ts\") <= F.col(\"session_end_ts\"),\n",
    "        ],\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .drop(\"s_user_id\", \"s_product_code\", \"ts\")\n",
    "    .withColumn(\n",
    "        \"session_start_ts\",\n",
    "        F.when(F.col(\"session_id\").isNotNull(), F.col(\"session_start_ts\"))\n",
    "         .otherwise(F.lit(None).cast(\"timestamp\"))\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"session_end_ts\",\n",
    "        F.when(F.col(\"session_id\").isNotNull(), F.col(\"session_end_ts\"))\n",
    "         .otherwise(F.lit(None).cast(\"timestamp\"))\n",
    "    )\n",
    "    .withColumn(\"event_date\", F.to_date(\"timestamp\"))\n",
    "    .select(\n",
    "        \"user_id\", \"event_id\", \"product_code\", \"timestamp\",\n",
    "        \"event_date\", \"session_start_ts\", \"session_end_ts\", \"session_id\"\n",
    "    )\n",
    ")\n",
    "\n",
    "updates.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c353f8b5-3b18-4174-ba3a-883df6deb696",
   "metadata": {},
   "source": [
    "# Step 8: Delete impacted users for [dmin .. dmax+1] and append fresh result (MERGE delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dac7cc7f-8940-44e1-a73b-a54676d169a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-25 00:59:27.270\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mevent_sessions.sessions.events_to_sessions\u001b[0m:\u001b[36mrewrite_impacted_users\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1mRewrote impacted users for dates [2025-09-18 .. 2025-09-21] from batch date=2025-09-20; table_version=1\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'ok',\n",
       " 'output_path': '/home/demon/jetbrains/github/sessions/data/demo/sessions',\n",
       " 'left_date': '2025-09-18',\n",
       " 'right_date': '2025-09-21',\n",
       " 'table_version': 1}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 8: Delete impacted users for [dmin .. dmax+1] and append fresh result (MERGE delete)\n",
    "\n",
    "# Repartition by event_date and a hash-based day_bucket to evenly distribute data and control files per day\n",
    "files_per_day = 1\n",
    "updates_b = updates.withColumn(\"day_bucket\", F.pmod(F.xxhash64(\"user_id\"), F.lit(files_per_day)))\n",
    "num_days = (write_right_date - write_left_date).days + 1\n",
    "updates = updates_b.repartition(num_days * files_per_day, \"event_date\", \"day_bucket\").drop(\"day_bucket\")\n",
    "\n",
    "rewrite_impacted_users(\n",
    "    spark=spark,\n",
    "    output_path=output_path,\n",
    "    impacted_keys=impacted_keys,\n",
    "    updates=updates,\n",
    "    write_left_date=write_left_date,\n",
    "    write_right_date=write_right_date,\n",
    "    run_date_str=run_date_str,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866300eb-1d8b-49be-9e6c-e979f03fae0c",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10fcbd91-1a24-4ac9-9662-ac6faf684c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample20250920.csv analysis\n",
    "\n",
    "# user_id,event_id,timestamp,product_code\n",
    "# u1,a,2025-09-18 09:00:00,pyc\n",
    "# u1,z,2025-09-18 09:03:00,pyc\n",
    "# u1,b,2025-09-18 09:04:59,pyc\n",
    "\n",
    "# u1,y,2025-09-18 09:10:30,pyc\n",
    "\n",
    "# u1,a,2025-09-18 10:00:00,pyc\n",
    "# u1,x,2025-09-18 10:02:00,pyc\n",
    "\n",
    "# u1,c,2025-09-18 10:07:01,pyc\n",
    "\n",
    "# u2,b,2025-09-20 23:58:00,pyc\n",
    "\n",
    "# u2,x,2025-09-20 00:02:00,pyc\n",
    "\n",
    "# u2,c,2025-09-20 00:02:59,pyc\n",
    "\n",
    "# u2,d,2025-09-20 00:10:00,pyc\n",
    "\n",
    "# u3,x,2025-09-18 12:00:00,idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fbadce2-0160-4d2e-b0d4-5217e9f729e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------------+-------------------+----------+-------------------+-------------------+-------------------------------+\n",
      "|user_id|event_id|product_code|timestamp          |event_date|session_start_ts   |session_end_ts     |session_id                     |\n",
      "+-------+--------+------------+-------------------+----------+-------------------+-------------------+-------------------------------+\n",
      "|u1     |a       |pyc         |2025-09-18 09:00:00|2025-09-18|2025-09-18 09:00:00|2025-09-18 09:09:59|u1#pyc#2025-09-18T09:00:00.000Z|\n",
      "|u1     |z       |pyc         |2025-09-18 09:03:00|2025-09-18|2025-09-18 09:00:00|2025-09-18 09:09:59|u1#pyc#2025-09-18T09:00:00.000Z|\n",
      "|u1     |b       |pyc         |2025-09-18 09:04:59|2025-09-18|2025-09-18 09:00:00|2025-09-18 09:09:59|u1#pyc#2025-09-18T09:00:00.000Z|\n",
      "|u1     |y       |pyc         |2025-09-18 09:10:30|2025-09-18|NULL               |NULL               |NULL                           |\n",
      "|u1     |a       |pyc         |2025-09-18 10:00:00|2025-09-18|2025-09-18 10:00:00|2025-09-18 10:05:00|u1#pyc#2025-09-18T10:00:00.000Z|\n",
      "|u1     |x       |pyc         |2025-09-18 10:02:00|2025-09-18|2025-09-18 10:00:00|2025-09-18 10:05:00|u1#pyc#2025-09-18T10:00:00.000Z|\n",
      "|u1     |c       |pyc         |2025-09-18 10:07:01|2025-09-18|2025-09-18 10:07:01|2025-09-18 10:12:01|u1#pyc#2025-09-18T10:07:01.000Z|\n",
      "|u2     |x       |pyc         |2025-09-20 00:02:00|2025-09-20|NULL               |NULL               |NULL                           |\n",
      "|u2     |c       |pyc         |2025-09-20 00:02:59|2025-09-20|2025-09-20 00:02:59|2025-09-20 00:07:59|u2#pyc#2025-09-20T00:02:59.000Z|\n",
      "|u2     |d       |pyc         |2025-09-20 00:10:00|2025-09-20|NULL               |NULL               |NULL                           |\n",
      "|u2     |b       |pyc         |2025-09-20 23:58:00|2025-09-20|2025-09-20 23:58:00|2025-09-21 00:03:00|u2#pyc#2025-09-20T23:58:00.000Z|\n",
      "|u3     |x       |idea        |2025-09-18 12:00:00|2025-09-18|NULL               |NULL               |NULL                           |\n",
      "+-------+--------+------------+-------------------+----------+-------------------+-------------------+-------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_result = spark.read.format(\"delta\").load(output_path)\n",
    "df_result.orderBy(\"user_id\", \"timestamp\").show(truncate=False, n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7a316e-8fd8-4d39-8a92-f7998f2b6d7d",
   "metadata": {},
   "source": [
    "# spark-submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acd1ec51-e61a-425e-8d63-5b978d862c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run in terminal\n",
    "# spark-submit --packages io.delta:delta-spark_2.12:3.2.0 src/event_sessions/sessions/events_to_sessions.py --run-date 2025-09-21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae5ab35d-9f4f-4676-aa30-f78551241b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample20250921.csv analysis\n",
    "\n",
    "# user_id,event_id,timestamp,product_code\n",
    "# u1,a,2025-09-18 09:00:00,pyc\n",
    "# u1,z,2025-09-18 09:03:00,pyc\n",
    "# u1,b,2025-09-18 09:04:59,pyc\n",
    "# u1,b,2025-09-18 09:08:59,pyc <- \"+\"\n",
    "# u1,y,2025-09-18 09:10:30,pyc <- \"new in session\"\n",
    "# u1,v,2025-09-18 09:10:50,pyc <- \"new in session\"\n",
    "\n",
    "# u1,a,2025-09-18 10:00:00,pyc\n",
    "# u1,x,2025-09-18 10:02:00,pyc\n",
    "\n",
    "# u1,c,2025-09-18 10:07:01,pyc\n",
    "\n",
    "# u2,b,2025-09-19 23:58:00,pyc <- \"new session (new user event)\"\n",
    "# u2,x,2025-09-20 00:02:00,pyc <- \"new in session\"\n",
    "# u2,c,2025-09-20 00:02:59,pyc <- \"new in session (new user event)\"\n",
    "# u2,a,2025-09-20 00:02:59,pyc <- \"new in session (new user event)\"\n",
    "\n",
    "# u2,d,2025-09-20 00:10:00,pyc <- \"same ide event without session\"\n",
    "\n",
    "# u3,a,2025-09-18 11:58:00,idea\n",
    "# u3,x,2025-09-18 12:00:00,idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98d1582f-b806-461b-ad2e-abb8849db9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------------+-------------------+----------+-------------------+-------------------+--------------------------------+\n",
      "|user_id|event_id|product_code|timestamp          |event_date|session_start_ts   |session_end_ts     |session_id                      |\n",
      "+-------+--------+------------+-------------------+----------+-------------------+-------------------+--------------------------------+\n",
      "|u1     |a       |pyc         |2025-09-18 09:00:00|2025-09-18|2025-09-18 09:00:00|2025-09-18 09:13:59|u1#pyc#2025-09-18T09:00:00.000Z |\n",
      "|u1     |z       |pyc         |2025-09-18 09:03:00|2025-09-18|2025-09-18 09:00:00|2025-09-18 09:13:59|u1#pyc#2025-09-18T09:00:00.000Z |\n",
      "|u1     |b       |pyc         |2025-09-18 09:04:59|2025-09-18|2025-09-18 09:00:00|2025-09-18 09:13:59|u1#pyc#2025-09-18T09:00:00.000Z |\n",
      "|u1     |b       |pyc         |2025-09-18 09:08:59|2025-09-18|2025-09-18 09:00:00|2025-09-18 09:13:59|u1#pyc#2025-09-18T09:00:00.000Z |\n",
      "|u1     |y       |pyc         |2025-09-18 09:10:30|2025-09-18|2025-09-18 09:00:00|2025-09-18 09:13:59|u1#pyc#2025-09-18T09:00:00.000Z |\n",
      "|u1     |v       |pyc         |2025-09-18 09:10:50|2025-09-18|2025-09-18 09:00:00|2025-09-18 09:13:59|u1#pyc#2025-09-18T09:00:00.000Z |\n",
      "|u1     |a       |pyc         |2025-09-18 10:00:00|2025-09-18|2025-09-18 10:00:00|2025-09-18 10:05:00|u1#pyc#2025-09-18T10:00:00.000Z |\n",
      "|u1     |x       |pyc         |2025-09-18 10:02:00|2025-09-18|2025-09-18 10:00:00|2025-09-18 10:05:00|u1#pyc#2025-09-18T10:00:00.000Z |\n",
      "|u1     |c       |pyc         |2025-09-18 10:07:01|2025-09-18|2025-09-18 10:07:01|2025-09-18 10:12:01|u1#pyc#2025-09-18T10:07:01.000Z |\n",
      "|u2     |b       |pyc         |2025-09-19 23:58:00|2025-09-19|2025-09-19 23:58:00|2025-09-20 00:07:59|u2#pyc#2025-09-19T23:58:00.000Z |\n",
      "|u2     |x       |pyc         |2025-09-20 00:02:00|2025-09-20|2025-09-19 23:58:00|2025-09-20 00:07:59|u2#pyc#2025-09-19T23:58:00.000Z |\n",
      "|u2     |c       |pyc         |2025-09-20 00:02:59|2025-09-20|2025-09-19 23:58:00|2025-09-20 00:07:59|u2#pyc#2025-09-19T23:58:00.000Z |\n",
      "|u2     |a       |pyc         |2025-09-20 00:02:59|2025-09-20|2025-09-19 23:58:00|2025-09-20 00:07:59|u2#pyc#2025-09-19T23:58:00.000Z |\n",
      "|u2     |d       |pyc         |2025-09-20 00:10:00|2025-09-20|NULL               |NULL               |NULL                            |\n",
      "|u3     |a       |idea        |2025-09-18 11:58:00|2025-09-18|2025-09-18 11:58:00|2025-09-18 12:03:00|u3#idea#2025-09-18T11:58:00.000Z|\n",
      "|u3     |x       |idea        |2025-09-18 12:00:00|2025-09-18|2025-09-18 11:58:00|2025-09-18 12:03:00|u3#idea#2025-09-18T11:58:00.000Z|\n",
      "+-------+--------+------------+-------------------+----------+-------------------+-------------------+--------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_result_20250921 = spark.read.format(\"delta\").load(output_path)\n",
    "df_result_20250921.orderBy(\"user_id\", \"timestamp\").show(truncate=False, n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec54908e-ece1-4048-9f15-cf2050030232",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "polars_gpu_pyspark",
   "language": "python",
   "name": "cudf_pyspark_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
